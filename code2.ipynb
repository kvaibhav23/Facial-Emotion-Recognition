{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11214584,"sourceType":"datasetVersion","datasetId":7002887},{"sourceId":11214601,"sourceType":"datasetVersion","datasetId":7002897}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:46:15.416742Z","iopub.execute_input":"2025-03-31T15:46:15.417017Z","iopub.status.idle":"2025-03-31T15:46:15.420743Z","shell.execute_reply.started":"2025-03-31T15:46:15.416996Z","shell.execute_reply":"2025-03-31T15:46:15.419864Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_path = '/kaggle/input/train-facial-expresssion/kaggle/working/train'\nprint(os.listdir(train_path))\ntest_path = '/kaggle/input/test-facial-expression/kaggle/working/test'\nprint(os.listdir(test_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:46:15.421734Z","iopub.execute_input":"2025-03-31T15:46:15.422072Z","iopub.status.idle":"2025-03-31T15:46:15.471535Z","shell.execute_reply.started":"2025-03-31T15:46:15.422041Z","shell.execute_reply":"2025-03-31T15:46:15.470705Z"}},"outputs":[{"name":"stdout","text":"['surprise', 'fear', 'angry', 'neutral', 'sad', 'disgust', 'happy']\n['surprise', 'fear', 'angry', 'neutral', 'sad', 'disgust', 'happy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Labelling the images\n","metadata":{}},{"cell_type":"code","source":"def load_dataset(dataset_path):\n    images = []\n    labels = []\n\n    for emotion in os.listdir(dataset_path):\n        emotion_path = os.path.join(dataset_path,emotion)\n        for image in os.listdir(emotion_path):\n            img_path = os.path.join(emotion_path,image)\n            images.append(img_path)\n            labels.append(emotion)\n\n    return images, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:46:15.472450Z","iopub.execute_input":"2025-03-31T15:46:15.472750Z","iopub.status.idle":"2025-03-31T15:46:15.478296Z","shell.execute_reply.started":"2025-03-31T15:46:15.472721Z","shell.execute_reply":"2025-03-31T15:46:15.477543Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\ntrain_path = '/kaggle/input/train-facial-expresssion/kaggle/working/train'\ntrain_df = pd.DataFrame()\ntrain_df['image'], train_df['label'] = load_dataset(train_path)\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:46:15.479191Z","iopub.execute_input":"2025-03-31T15:46:15.479450Z","iopub.status.idle":"2025-03-31T15:46:18.269018Z","shell.execute_reply.started":"2025-03-31T15:46:15.479431Z","shell.execute_reply":"2025-03-31T15:46:18.268213Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               image     label\n0  /kaggle/input/train-facial-expresssion/kaggle/...  surprise\n1  /kaggle/input/train-facial-expresssion/kaggle/...  surprise\n2  /kaggle/input/train-facial-expresssion/kaggle/...  surprise\n3  /kaggle/input/train-facial-expresssion/kaggle/...  surprise\n4  /kaggle/input/train-facial-expresssion/kaggle/...  surprise","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/train-facial-expresssion/kaggle/...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/train-facial-expresssion/kaggle/...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/train-facial-expresssion/kaggle/...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/train-facial-expresssion/kaggle/...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/train-facial-expresssion/kaggle/...</td>\n      <td>surprise</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define constants\nIMG_SIZE = (48, 48)  \nBATCH_SIZE = 64\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n# test_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load data using generators\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"grayscale\",\n    class_mode='categorical',\n    shuffle=True\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"grayscale\",\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Function to load entire dataset into memory efficiently\ndef load_data(generator):\n    X, y = [], []\n    for img_batch, label_batch in generator:\n        X.append(img_batch)\n        y.append(label_batch)\n        if len(X) * BATCH_SIZE >= generator.samples:\n            break  # Stop when all images are loaded\n    return np.concatenate(X), np.concatenate(y)\n\n# Load train and test data\nX_train, y_train = load_data(train_generator)\nX_test, y_test = load_data(test_generator)\n\n# Print dataset shapes\nprint(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T16:23:03.033221Z","iopub.execute_input":"2025-03-31T16:23:03.033547Z","iopub.status.idle":"2025-03-31T16:24:12.936433Z","shell.execute_reply.started":"2025-03-31T16:23:03.033519Z","shell.execute_reply":"2025-03-31T16:24:12.935539Z"}},"outputs":[{"name":"stdout","text":"Found 28229 images belonging to 7 classes.\nFound 5760 images belonging to 7 classes.\nX_train shape: (28229, 48, 48, 1), y_train shape: (28229, 7)\nX_test shape: (5760, 48, 48, 1), y_test shape: (5760, 7)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ntrain_df = train_df.sample(frac=1, random_state=0)  \nlabel_column = train_df[['label']]\nencoder = OneHotEncoder(sparse_output=False)\none_hot_encoded = encoder.fit_transform(label_column)\ncolumn_names = encoder.get_feature_names_out(['label'])\none_hot_df = pd.DataFrame(one_hot_encoded, columns=column_names)\ntrain_encoded = pd.concat([train_df[['image']], one_hot_df], axis=1)\nprint(train_encoded.iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T16:24:35.277301Z","iopub.execute_input":"2025-03-31T16:24:35.277590Z","iopub.status.idle":"2025-03-31T16:24:35.302370Z","shell.execute_reply.started":"2025-03-31T16:24:35.277568Z","shell.execute_reply":"2025-03-31T16:24:35.301631Z"}},"outputs":[{"name":"stdout","text":"image             /kaggle/input/train-facial-expresssion/kaggle/...\nlabel_angry                                                     0.0\nlabel_disgust                                                   0.0\nlabel_fear                                                      0.0\nlabel_happy                                                     0.0\nlabel_neutral                                                   0.0\nlabel_sad                                                       1.0\nlabel_surprise                                                  0.0\nName: 7648, dtype: object\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential([\n    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(48, 48, 1)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    \n\n    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(7, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',  # Change to sparse_categorical_crossentropy if labels are integers\n              metrics=['accuracy'])\n\nmodel.summary()  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T16:24:41.651199Z","iopub.execute_input":"2025-03-31T16:24:41.651546Z","iopub.status.idle":"2025-03-31T16:24:41.759553Z","shell.execute_reply.started":"2025-03-31T16:24:41.651517Z","shell.execute_reply":"2025-03-31T16:24:41.758885Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m1,180,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m2,359,808\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m3,591\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,917,063\u001b[0m (14.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,917,063</span> (14.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,915,143\u001b[0m (14.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,915,143</span> (14.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Reduce learning rate when validation loss stops improving\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_loss',  # Track validation loss\n    patience=3,          # Wait 3 epochs before reducing LR\n    factor=0.5,          # Reduce LR by a factor of 0.5\n    min_lr=1e-7          # Minimum LR to prevent excessive reduction\n)\n\nhistory = model.fit(\n    train_generator,\n    epochs=71,  # You can increase epochs if needed\n    validation_data=test_generator,\n    steps_per_epoch=len(train_generator),\n    validation_steps=len(test_generator),\n    callbacks=[lr_scheduler]  # Add learning rate scheduler here\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T16:41:11.357649Z","iopub.execute_input":"2025-03-31T16:41:11.358000Z","iopub.status.idle":"2025-03-31T17:11:04.988634Z","shell.execute_reply.started":"2025-03-31T16:41:11.357970Z","shell.execute_reply":"2025-03-31T17:11:04.987906Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.9860 - loss: 0.0429 - val_accuracy: 0.6087 - val_loss: 2.5791 - learning_rate: 1.2500e-04\nEpoch 2/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2500e-04\nEpoch 3/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.9877 - loss: 0.0397 - val_accuracy: 0.6146 - val_loss: 2.7576 - learning_rate: 1.2500e-04\nEpoch 4/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2500e-04\nEpoch 5/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 117ms/step - accuracy: 0.9889 - loss: 0.0358 - val_accuracy: 0.6161 - val_loss: 2.8544 - learning_rate: 1.2500e-04\nEpoch 6/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2500e-04\nEpoch 7/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.9903 - loss: 0.0302 - val_accuracy: 0.6118 - val_loss: 2.8382 - learning_rate: 1.2500e-04\nEpoch 8/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 6.2500e-05\nEpoch 9/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9922 - loss: 0.0261 - val_accuracy: 0.6144 - val_loss: 2.9815 - learning_rate: 6.2500e-05\nEpoch 10/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 6.2500e-05\nEpoch 11/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9929 - loss: 0.0250 - val_accuracy: 0.6151 - val_loss: 3.0468 - learning_rate: 6.2500e-05\nEpoch 12/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 6.2500e-05\nEpoch 13/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.6139 - val_loss: 3.0609 - learning_rate: 6.2500e-05\nEpoch 14/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.1250e-05\nEpoch 15/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.6170 - val_loss: 3.1612 - learning_rate: 3.1250e-05\nEpoch 16/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.1250e-05\nEpoch 17/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 119ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 0.6198 - val_loss: 3.1964 - learning_rate: 3.1250e-05\nEpoch 18/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.1250e-05\nEpoch 19/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9957 - loss: 0.0153 - val_accuracy: 0.6207 - val_loss: 3.2124 - learning_rate: 3.1250e-05\nEpoch 20/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.5625e-05\nEpoch 21/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9958 - loss: 0.0136 - val_accuracy: 0.6198 - val_loss: 3.2447 - learning_rate: 1.5625e-05\nEpoch 22/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.5625e-05\nEpoch 23/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 110ms/step - accuracy: 0.9963 - loss: 0.0126 - val_accuracy: 0.6193 - val_loss: 3.2636 - learning_rate: 1.5625e-05\nEpoch 24/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.5625e-05\nEpoch 25/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.6203 - val_loss: 3.2796 - learning_rate: 1.5625e-05\nEpoch 26/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 7.8125e-06\nEpoch 27/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 110ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.6193 - val_loss: 3.2807 - learning_rate: 7.8125e-06\nEpoch 28/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 7.8125e-06\nEpoch 29/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.6193 - val_loss: 3.3002 - learning_rate: 7.8125e-06\nEpoch 30/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 7.8125e-06\nEpoch 31/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.6189 - val_loss: 3.3112 - learning_rate: 7.8125e-06\nEpoch 32/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.9063e-06\nEpoch 33/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 111ms/step - accuracy: 0.9960 - loss: 0.0114 - val_accuracy: 0.6196 - val_loss: 3.3143 - learning_rate: 3.9063e-06\nEpoch 34/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.9063e-06\nEpoch 35/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.6207 - val_loss: 3.3272 - learning_rate: 3.9063e-06\nEpoch 36/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 3.9063e-06\nEpoch 37/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.9959 - loss: 0.0124 - val_accuracy: 0.6207 - val_loss: 3.3310 - learning_rate: 3.9063e-06\nEpoch 38/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.9531e-06\nEpoch 39/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9955 - loss: 0.0126 - val_accuracy: 0.6187 - val_loss: 3.3279 - learning_rate: 1.9531e-06\nEpoch 40/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.9531e-06\nEpoch 41/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 110ms/step - accuracy: 0.9968 - loss: 0.0110 - val_accuracy: 0.6203 - val_loss: 3.3275 - learning_rate: 1.9531e-06\nEpoch 42/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.9531e-06\nEpoch 43/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.9961 - loss: 0.0123 - val_accuracy: 0.6207 - val_loss: 3.3419 - learning_rate: 1.9531e-06\nEpoch 44/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 9.7656e-07\nEpoch 45/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.6205 - val_loss: 3.3397 - learning_rate: 9.7656e-07\nEpoch 46/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 9.7656e-07\nEpoch 47/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.6198 - val_loss: 3.3389 - learning_rate: 9.7656e-07\nEpoch 48/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 9.7656e-07\nEpoch 49/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.9968 - loss: 0.0112 - val_accuracy: 0.6200 - val_loss: 3.3391 - learning_rate: 9.7656e-07\nEpoch 50/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 4.8828e-07\nEpoch 51/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9960 - loss: 0.0131 - val_accuracy: 0.6205 - val_loss: 3.3364 - learning_rate: 4.8828e-07\nEpoch 52/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 4.8828e-07\nEpoch 53/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.6207 - val_loss: 3.3401 - learning_rate: 4.8828e-07\nEpoch 54/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 4.8828e-07\nEpoch 55/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.6212 - val_loss: 3.3387 - learning_rate: 4.8828e-07\nEpoch 56/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 2.4414e-07\nEpoch 57/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.9961 - loss: 0.0117 - val_accuracy: 0.6210 - val_loss: 3.3463 - learning_rate: 2.4414e-07\nEpoch 58/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 2.4414e-07\nEpoch 59/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.9960 - loss: 0.0108 - val_accuracy: 0.6212 - val_loss: 3.3360 - learning_rate: 2.4414e-07\nEpoch 60/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 2.4414e-07\nEpoch 61/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.6207 - val_loss: 3.3492 - learning_rate: 2.4414e-07\nEpoch 62/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2207e-07\nEpoch 63/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 108ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 0.6208 - val_loss: 3.3460 - learning_rate: 1.2207e-07\nEpoch 64/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2207e-07\nEpoch 65/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.6205 - val_loss: 3.3432 - learning_rate: 1.2207e-07\nEpoch 66/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.2207e-07\nEpoch 67/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.6214 - val_loss: 3.3446 - learning_rate: 1.2207e-07\nEpoch 68/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.0000e-07\nEpoch 69/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.9962 - loss: 0.0106 - val_accuracy: 0.6201 - val_loss: 3.3472 - learning_rate: 1.0000e-07\nEpoch 70/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 1.0000e-07\nEpoch 71/71\n\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.6208 - val_loss: 3.3407 - learning_rate: 1.0000e-07\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Save the new model\nmodel.save(\"model1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T17:14:06.774499Z","iopub.execute_input":"2025-03-31T17:14:06.774813Z","iopub.status.idle":"2025-03-31T17:14:06.943830Z","shell.execute_reply.started":"2025-03-31T17:14:06.774786Z","shell.execute_reply":"2025-03-31T17:14:06.942906Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"final_train_acc = history.history[\"accuracy\"][-1]  # Last epoch train accuracy\nfinal_val_acc = history.history[\"val_accuracy\"][-1]  # Last epoch validation accuracy\n\nprint(f\"Final Training Accuracy: {final_train_acc * 100:.2f}%\")\nprint(f\"Final Validation Accuracy: {final_val_acc * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T17:15:48.056186Z","iopub.execute_input":"2025-03-31T17:15:48.056533Z","iopub.status.idle":"2025-03-31T17:15:48.061790Z","shell.execute_reply.started":"2025-03-31T17:15:48.056505Z","shell.execute_reply":"2025-03-31T17:15:48.060877Z"}},"outputs":[{"name":"stdout","text":"Final Training Accuracy: 99.61%\nFinal Validation Accuracy: 62.08%\n","output_type":"stream"}],"execution_count":26}]}